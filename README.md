# Awesome Natural Language Generation
A curated list of Natural Language Generation papers, tutorials, and blogs.

## Introduction
In the most widely-cited survey of Natural Language Generation methods([Building natural language generation systems](https://books.google.com/books?hl=en&lr=&id=qnWQU9C8bDkC&oi=fnd&pg=PP1&dq=building+natural+language+generation+systems&ots=j-2Pds_odB&sig=nnQkzh-X1Y_haxTGECjpHl445xo#v=onepage&q=building%20natural%20language%20generation%20systems&f=false)), Natural Language Generation is characterized as "the subfield of artificial intelligence and computational linguistics that is concerned with the construction of computer systems than can produce understandable texts in English or other human languages from some underlying non-linguistic representation of information". Therefore, the terms "Natural Language Generation" and "NLG" are commonly used to refer to systems that generate text from non-linguistic data. The goal of Natural Language Generation is to generate text that can adequately and fluently describes the given data, which is usually a set of data records like table.

## Table of contents
- [Blog posts](#blog-posts)
- [Datasets](#datasets)
- [Papers](#papers)
    - [Survey papers](#survey-papers)
    - [Modular methods](#modular-methods)
    - [Neural network approaches](#neural-network-approaches)

## Blog posts
* https://ehudreiter.com/

## Datasets
* RoboCup(2008)
* WeatherGov(2009)
* WikiBio(2016)[[Link]](https://github.com/DavidGrangier/wikipedia-biography-dataset)
* RotoWire & SBNation(2017)[[Link]](https://github.com/harvardnlp/boxscore-data)


## Papers
### Survey papers
* [Building natural language generation systems](https://books.google.com/books?hl=en&lr=&id=qnWQU9C8bDkC&oi=fnd&pg=PP1&dq=building+natural+language+generation+systems&ots=j-2Pds_odB&sig=nnQkzh-X1Y_haxTGECjpHl445xo#v=onepage&q=building%20natural%20language%20generation%20systems&f=false)(1997)
* [Natural Language Generation](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781444324044.ch20)(2010)
* [Survey of the State of the Art in Natural Language Generation](https://arxiv.org/pdf/1703.09902.pdf)(2017)
* [Neural Text Generation: A Practical Guide](https://arxiv.org/pdf/1711.09534.pdf)(2017)
* [Neural Text Generation: Past, Present and Beyond](https://arxiv.org/pdf/1803.07133.pdf)(2018)

### Modular methods
* [Design of a Knowledge-Based Report Generator](https://aclanthology.info/pdf/P/P83/P83-1022.pdf)(1983)
* [Building Applied Natural Language Generation Systems](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/FEB374A3FF652F06D8567A6FAB2EF36E/S1351324997001502a.pdf/div-class-title-building-applied-natural-language-generation-systems-div.pdf)(1997)
* [A simple domain-independent probabilistic approach to generation](http://www.aclweb.org/anthology/D10-1049)(EMNLP, 2010)
* [Unsupervised concept-to-text generation with hypergraphs](https://aclanthology.info/pdf/N/N12/N12-1093.pdf)(NAACL, 2012)
* [Inducing document plans for concept-to-text generation](http://www.aclweb.org/anthology/D13-1157)(2013)


### Neural network approaches
* [Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data](http://www.aclweb.org/anthology/P18-1154)(ACL, 2018)[[Code]](https://github.com/harsh19/ChessCommentaryGeneration)
* [Scalable Micro-planned Generation of Discourse from Structured Data](https://arxiv.org/pdf/1810.02889.pdf)(2018)
* [A mixed hierarchical attention based encoder-decoder approach for standard table summarization](https://arxiv.org/pdf/1804.07790.pdf)(2018)
* [Generating Descriptions from Structured Data Using a Bifocal Attention Mechanism and Gated Orthogonalization](https://arxiv.org/pdf/1804.07789.pdf)(2018)
* [Data-to-Text Generation with Content Selection and Planning](https://arxiv.org/pdf/1809.00582.pdf)(2018)
* [Bootstrapping Generators from Noisy Data](http://aclweb.org/anthology/N18-1137)(NAACL, 2018)
* [Table-to-Text: Describing Table Region with Natural Language](https://arxiv.org/pdf/1805.11234.pdf)(AAAI, 2018)
* [Table-to-text Generation by Structure-aware Seq2seq Learning](https://arxiv.org/pdf/1711.09724.pdf)(AAAI, 2018)[[Code]](https://github.com/tyliupku/wiki2bio)
* [Challenges in Data-to-Document Generation](https://aclweb.org/anthology/D17-1239)(EMNLP, 2017)[[Code]](https://github.com/harvardnlp/data2text)[[Datasets]](https://github.com/harvardnlp/boxscore-data)
* [Order-Planning Neural Text Generation From Structured Data](https://arxiv.org/pdf/1709.00155.pdf)(2017)[[Code]](https://github.com/akanimax/natural-language-summary-generation-from-structured-data)
* [Neural Text Generation from Structured Data with Application to the Biography Domain](https://arxiv.org/pdf/1603.07771.pdf)(EMNLP, 2016)[[Dataset]](https://github.com/DavidGrangier/wikipedia-biography-dataset)
* [What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment](http://www.aclweb.org/anthology/N16-1086)(NAACL, 2016)

## Contact & Feedback
If you have any suggestions, please feel free to email me at tianwei.she@yale.edu.
